RSB
(320, 240, 3)
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to
==================================================================================================
 input_1 (InputLayer)           [(None, 240, 320, 3  0           []
                                )]
 conv2d (Conv2D)                (None, 236, 316, 64  4864        ['input_1[0][0]']
                                )
 batch_normalization (BatchNorm  (None, 236, 316, 64  256        ['conv2d[0][0]']
 alization)                     )
 activation (Activation)        (None, 236, 316, 64  0           ['batch_normalization[0][0]']
                                )
 max_pooling2d (MaxPooling2D)   (None, 117, 157, 64  0           ['activation[0][0]']
                                )
 conv2d_1 (Conv2D)              (None, 59, 79, 64)   4160        ['max_pooling2d[0][0]']
 batch_normalization_1 (BatchNo  (None, 59, 79, 64)  256         ['conv2d_1[0][0]']
 rmalization)
 activation_1 (Activation)      (None, 59, 79, 64)   0           ['batch_normalization_1[0][0]']
 conv2d_2 (Conv2D)              (None, 59, 79, 64)   36928       ['activation_1[0][0]']
 batch_normalization_2 (BatchNo  (None, 59, 79, 64)  256         ['conv2d_2[0][0]']
 rmalization)
 activation_2 (Activation)      (None, 59, 79, 64)   0           ['batch_normalization_2[0][0]']
 conv2d_3 (Conv2D)              (None, 59, 79, 128)  8320        ['activation_2[0][0]']
 conv2d_4 (Conv2D)              (None, 59, 79, 128)  8320        ['max_pooling2d[0][0]']
 batch_normalization_3 (BatchNo  (None, 59, 79, 128)  512        ['conv2d_3[0][0]']
 rmalization)
 batch_normalization_4 (BatchNo  (None, 59, 79, 128)  512        ['conv2d_4[0][0]']
 rmalization)
 add (Add)                      (None, 59, 79, 128)  0           ['batch_normalization_3[0][0]',
                                                                  'batch_normalization_4[0][0]']
 activation_3 (Activation)      (None, 59, 79, 128)  0           ['add[0][0]']
 conv2d_5 (Conv2D)              (None, 59, 79, 64)   8256        ['activation_3[0][0]']
 batch_normalization_5 (BatchNo  (None, 59, 79, 64)  256         ['conv2d_5[0][0]']
 rmalization)
 activation_4 (Activation)      (None, 59, 79, 64)   0           ['batch_normalization_5[0][0]']
 conv2d_6 (Conv2D)              (None, 59, 79, 64)   36928       ['activation_4[0][0]']
 batch_normalization_6 (BatchNo  (None, 59, 79, 64)  256         ['conv2d_6[0][0]']
 rmalization)
 activation_5 (Activation)      (None, 59, 79, 64)   0           ['batch_normalization_6[0][0]']
 conv2d_7 (Conv2D)              (None, 59, 79, 128)  8320        ['activation_5[0][0]']
 batch_normalization_7 (BatchNo  (None, 59, 79, 128)  512        ['conv2d_7[0][0]']
 rmalization)
 add_1 (Add)                    (None, 59, 79, 128)  0           ['batch_normalization_7[0][0]',
                                                                  'activation_3[0][0]']
 activation_6 (Activation)      (None, 59, 79, 128)  0           ['add_1[0][0]']
 conv2d_8 (Conv2D)              (None, 59, 79, 64)   8256        ['activation_6[0][0]']
 batch_normalization_8 (BatchNo  (None, 59, 79, 64)  256         ['conv2d_8[0][0]']
 rmalization)
 activation_7 (Activation)      (None, 59, 79, 64)   0           ['batch_normalization_8[0][0]']
 conv2d_9 (Conv2D)              (None, 59, 79, 64)   36928       ['activation_7[0][0]']
 batch_normalization_9 (BatchNo  (None, 59, 79, 64)  256         ['conv2d_9[0][0]']
 rmalization)
 activation_8 (Activation)      (None, 59, 79, 64)   0           ['batch_normalization_9[0][0]']
 conv2d_10 (Conv2D)             (None, 59, 79, 128)  8320        ['activation_8[0][0]']
 batch_normalization_10 (BatchN  (None, 59, 79, 128)  512        ['conv2d_10[0][0]']
 ormalization)
 add_2 (Add)                    (None, 59, 79, 128)  0           ['batch_normalization_10[0][0]',
                                                                  'activation_6[0][0]']
 activation_9 (Activation)      (None, 59, 79, 128)  0           ['add_2[0][0]']
 conv2d_11 (Conv2D)             (None, 30, 40, 128)  16512       ['activation_9[0][0]']
 batch_normalization_11 (BatchN  (None, 30, 40, 128)  512        ['conv2d_11[0][0]']
 ormalization)
 activation_10 (Activation)     (None, 30, 40, 128)  0           ['batch_normalization_11[0][0]']
 conv2d_12 (Conv2D)             (None, 30, 40, 128)  147584      ['activation_10[0][0]']
 batch_normalization_12 (BatchN  (None, 30, 40, 128)  512        ['conv2d_12[0][0]']
 ormalization)
 activation_11 (Activation)     (None, 30, 40, 128)  0           ['batch_normalization_12[0][0]']
 conv2d_13 (Conv2D)             (None, 30, 40, 256)  33024       ['activation_11[0][0]']
 conv2d_14 (Conv2D)             (None, 30, 40, 256)  33024       ['activation_9[0][0]']
 batch_normalization_13 (BatchN  (None, 30, 40, 256)  1024       ['conv2d_13[0][0]']
 ormalization)
 batch_normalization_14 (BatchN  (None, 30, 40, 256)  1024       ['conv2d_14[0][0]']
 ormalization)
 add_3 (Add)                    (None, 30, 40, 256)  0           ['batch_normalization_13[0][0]',
                                                                  'batch_normalization_14[0][0]']
 activation_12 (Activation)     (None, 30, 40, 256)  0           ['add_3[0][0]']
 conv2d_15 (Conv2D)             (None, 30, 40, 128)  32896       ['activation_12[0][0]']
 batch_normalization_15 (BatchN  (None, 30, 40, 128)  512        ['conv2d_15[0][0]']
 ormalization)
 activation_13 (Activation)     (None, 30, 40, 128)  0           ['batch_normalization_15[0][0]']
 conv2d_16 (Conv2D)             (None, 30, 40, 128)  147584      ['activation_13[0][0]']
 batch_normalization_16 (BatchN  (None, 30, 40, 128)  512        ['conv2d_16[0][0]']
 ormalization)
 activation_14 (Activation)     (None, 30, 40, 128)  0           ['batch_normalization_16[0][0]']
 conv2d_17 (Conv2D)             (None, 30, 40, 256)  33024       ['activation_14[0][0]']
 batch_normalization_17 (BatchN  (None, 30, 40, 256)  1024       ['conv2d_17[0][0]']
 ormalization)
 add_4 (Add)                    (None, 30, 40, 256)  0           ['batch_normalization_17[0][0]',
                                                                  'activation_12[0][0]']
 activation_15 (Activation)     (None, 30, 40, 256)  0           ['add_4[0][0]']
 conv2d_18 (Conv2D)             (None, 30, 40, 128)  32896       ['activation_15[0][0]']
 batch_normalization_18 (BatchN  (None, 30, 40, 128)  512        ['conv2d_18[0][0]']
 ormalization)
 activation_16 (Activation)     (None, 30, 40, 128)  0           ['batch_normalization_18[0][0]']
 conv2d_19 (Conv2D)             (None, 30, 40, 128)  147584      ['activation_16[0][0]']
 batch_normalization_19 (BatchN  (None, 30, 40, 128)  512        ['conv2d_19[0][0]']
 ormalization)
 activation_17 (Activation)     (None, 30, 40, 128)  0           ['batch_normalization_19[0][0]']
 conv2d_20 (Conv2D)             (None, 30, 40, 256)  33024       ['activation_17[0][0]']
 batch_normalization_20 (BatchN  (None, 30, 40, 256)  1024       ['conv2d_20[0][0]']
 ormalization)
 add_5 (Add)                    (None, 30, 40, 256)  0           ['batch_normalization_20[0][0]',
                                                                  'activation_15[0][0]']
 activation_18 (Activation)     (None, 30, 40, 256)  0           ['add_5[0][0]']
 conv2d_21 (Conv2D)             (None, 30, 40, 128)  32896       ['activation_18[0][0]']
 batch_normalization_21 (BatchN  (None, 30, 40, 128)  512        ['conv2d_21[0][0]']
 ormalization)
 activation_19 (Activation)     (None, 30, 40, 128)  0           ['batch_normalization_21[0][0]']
 conv2d_22 (Conv2D)             (None, 30, 40, 128)  147584      ['activation_19[0][0]']
 batch_normalization_22 (BatchN  (None, 30, 40, 128)  512        ['conv2d_22[0][0]']
 ormalization)
 activation_20 (Activation)     (None, 30, 40, 128)  0           ['batch_normalization_22[0][0]']
 conv2d_23 (Conv2D)             (None, 30, 40, 256)  33024       ['activation_20[0][0]']
 batch_normalization_23 (BatchN  (None, 30, 40, 256)  1024       ['conv2d_23[0][0]']
 ormalization)
 add_6 (Add)                    (None, 30, 40, 256)  0           ['batch_normalization_23[0][0]',
                                                                  'activation_18[0][0]']
 activation_21 (Activation)     (None, 30, 40, 256)  0           ['add_6[0][0]']
 conv2d_24 (Conv2D)             (None, 30, 40, 256)  590080      ['activation_21[0][0]']
 lambda_1 (Lambda)              (None, 58, 78, 128)  0           ['activation_9[0][0]']
 batch_normalization_24 (BatchN  (None, 30, 40, 256)  1024       ['conv2d_24[0][0]']
 ormalization)
 zero_padding2d_1 (ZeroPadding2  (None, 60, 80, 128)  0          ['lambda_1[0][0]']
 D)
 up_sampling2d (UpSampling2D)   (None, 60, 80, 256)  0           ['batch_normalization_24[0][0]']
 conv2d_25 (Conv2D)             (None, 60, 80, 256)  295168      ['zero_padding2d_1[0][0]']
 lambda (Lambda)                (None, 58, 78, 256)  0           ['up_sampling2d[0][0]']
 batch_normalization_25 (BatchN  (None, 60, 80, 256)  1024       ['conv2d_25[0][0]']
 ormalization)
 zero_padding2d (ZeroPadding2D)  (None, 60, 80, 256)  0          ['lambda[0][0]']
 concatenate (Concatenate)      (None, 60, 80, 512)  0           ['batch_normalization_25[0][0]',
                                                                  'zero_padding2d[0][0]']
 conv2d_26 (Conv2D)             (None, 60, 80, 256)  1179904     ['concatenate[0][0]']
 batch_normalization_26 (BatchN  (None, 60, 80, 256)  1024       ['conv2d_26[0][0]']
 ormalization)
 up_sampling2d_1 (UpSampling2D)  (None, 120, 160, 25  0          ['batch_normalization_26[0][0]']
                                6)
 zero_padding2d_2 (ZeroPadding2  (None, 240, 320, 64  0          ['conv2d[0][0]']
 D)                             )
 conv2d_27 (Conv2D)             (None, 120, 160, 12  295040      ['up_sampling2d_1[0][0]']
                                8)
 conv2d_28 (Conv2D)             (None, 240, 320, 12  73856       ['zero_padding2d_2[0][0]']
                                8)
 batch_normalization_27 (BatchN  (None, 120, 160, 12  512        ['conv2d_27[0][0]']
 ormalization)                  8)
 batch_normalization_28 (BatchN  (None, 240, 320, 12  512        ['conv2d_28[0][0]']
 ormalization)                  8)
 up_sampling2d_2 (UpSampling2D)  (None, 240, 320, 12  0          ['batch_normalization_27[0][0]']
                                8)
 concatenate_1 (Concatenate)    (None, 240, 320, 25  0           ['batch_normalization_28[0][0]',
                                6)                                'up_sampling2d_2[0][0]']
 conv2d_29 (Conv2D)             (None, 240, 320, 12  295040      ['concatenate_1[0][0]']
                                8)
 batch_normalization_29 (BatchN  (None, 240, 320, 12  512        ['conv2d_29[0][0]']
 ormalization)                  8)
 conv2d_30 (Conv2D)             (None, 240, 320, 64  73792       ['batch_normalization_29[0][0]']
                                )
 batch_normalization_30 (BatchN  (None, 240, 320, 64  256        ['conv2d_30[0][0]']
 ormalization)                  )
 conv2d_31 (Conv2D)             (None, 240, 320, 2)  1154        ['batch_normalization_30[0][0]']
==================================================================================================
Total params: 3,862,210
Trainable params: 3,853,250
Non-trainable params: 8,960
__________________________________________________________________________________________________
None
Found 1525 images belonging to 1 classes.
Found 1525 images belonging to 1 classes.
/home/boostfish/miniconda3/lib/python3.10/site-packages/keras/optimizers/legacy/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.
  super().__init__(name, **kwargs)
Epoch 1/50



5/5 [==============================] - ETA: 0s - loss: 0.6987 - accuracy: 0.4881
Epoch 1: loss improved from inf to 0.69870, saving model to ckpt/suimnet_rsb_n2.hdf5
5/5 [==============================] - 40s 7s/step - loss: 0.6987 - accuracy: 0.4881
Epoch 2/50



5/5 [==============================] - ETA: 0s - loss: 0.6444 - accuracy: 0.5087
Epoch 2: loss improved from 0.69870 to 0.64440, saving model to ckpt/suimnet_rsb_n2.hdf5
5/5 [==============================] - 34s 8s/step - loss: 0.6444 - accuracy: 0.5087
Epoch 3/50



5/5 [==============================] - ETA: 0s - loss: 0.4653 - accuracy: 0.4831
Epoch 3: loss improved from 0.64440 to 0.46529, saving model to ckpt/suimnet_rsb_n2.hdf5
5/5 [==============================] - 35s 9s/step - loss: 0.4653 - accuracy: 0.4831
Epoch 4/50



5/5 [==============================] - ETA: 0s - loss: 0.4706 - accuracy: 0.4943
Epoch 4: loss did not improve from 0.46529
5/5 [==============================] - 29s 7s/step - loss: 0.4706 - accuracy: 0.4943
Epoch 5/50



5/5 [==============================] - ETA: 0s - loss: 0.6345 - accuracy: 0.5309
Epoch 5: loss did not improve from 0.46529
5/5 [==============================] - 35s 7s/step - loss: 0.6345 - accuracy: 0.5309
Epoch 6/50



5/5 [==============================] - ETA: 0s - loss: 0.5884 - accuracy: 0.5436
Epoch 6: loss did not improve from 0.46529
5/5 [==============================] - 37s 7s/step - loss: 0.5884 - accuracy: 0.5436
Epoch 7/50



5/5 [==============================] - ETA: 0s - loss: 0.5614 - accuracy: 0.5074
Epoch 7: loss did not improve from 0.46529
5/5 [==============================] - 34s 7s/step - loss: 0.5614 - accuracy: 0.5074
Epoch 8/50



5/5 [==============================] - ETA: 0s - loss: 0.5670 - accuracy: 0.4823
Epoch 8: loss did not improve from 0.46529
5/5 [==============================] - 35s 7s/step - loss: 0.5670 - accuracy: 0.4823
Epoch 9/50



5/5 [==============================] - ETA: 0s - loss: 0.5853 - accuracy: 0.4994
Epoch 9: loss did not improve from 0.46529
5/5 [==============================] - 34s 7s/step - loss: 0.5853 - accuracy: 0.4994
Epoch 10/50



5/5 [==============================] - ETA: 0s - loss: 0.5336 - accuracy: 0.5037
Epoch 10: loss did not improve from 0.46529
5/5 [==============================] - 34s 7s/step - loss: 0.5336 - accuracy: 0.5037
Epoch 11/50



5/5 [==============================] - ETA: 0s - loss: 0.4658 - accuracy: 0.5192
Epoch 11: loss did not improve from 0.46529
5/5 [==============================] - 36s 7s/step - loss: 0.4658 - accuracy: 0.5192
Epoch 12/50



5/5 [==============================] - ETA: 0s - loss: 0.5376 - accuracy: 0.5046
Epoch 12: loss did not improve from 0.46529
5/5 [==============================] - 34s 7s/step - loss: 0.5376 - accuracy: 0.5046
Epoch 13/50



5/5 [==============================] - ETA: 0s - loss: 0.5003 - accuracy: 0.4998
Epoch 13: loss did not improve from 0.46529
5/5 [==============================] - 34s 7s/step - loss: 0.5003 - accuracy: 0.4998
Epoch 14/50



5/5 [==============================] - ETA: 0s - loss: 0.5900 - accuracy: 0.5363
Epoch 14: loss did not improve from 0.46529
5/5 [==============================] - 35s 7s/step - loss: 0.5900 - accuracy: 0.5363
Epoch 15/50



5/5 [==============================] - ETA: 0s - loss: 0.5836 - accuracy: 0.5549
Epoch 15: loss did not improve from 0.46529
5/5 [==============================] - 35s 7s/step - loss: 0.5836 - accuracy: 0.5549
Epoch 16/50



5/5 [==============================] - ETA: 0s - loss: 0.5286 - accuracy: 0.5211
Epoch 16: loss did not improve from 0.46529
5/5 [==============================] - 34s 7s/step - loss: 0.5286 - accuracy: 0.5211
Epoch 17/50



5/5 [==============================] - ETA: 0s - loss: 0.5119 - accuracy: 0.4948
Epoch 17: loss did not improve from 0.46529
5/5 [==============================] - 34s 7s/step - loss: 0.5119 - accuracy: 0.4948
Epoch 18/50



5/5 [==============================] - ETA: 0s - loss: 0.4985 - accuracy: 0.4830
Epoch 18: loss did not improve from 0.46529
5/5 [==============================] - 33s 7s/step - loss: 0.4985 - accuracy: 0.4830
Epoch 19/50



5/5 [==============================] - ETA: 0s - loss: 0.5298 - accuracy: 0.4772
Epoch 19: loss did not improve from 0.46529
5/5 [==============================] - 34s 7s/step - loss: 0.5298 - accuracy: 0.4772
Epoch 20/50




5/5 [==============================] - ETA: 0s - loss: 0.4674 - accuracy: 0.4878
Epoch 20: loss did not improve from 0.46529
5/5 [==============================] - 35s 7s/step - loss: 0.4674 - accuracy: 0.4878
Epoch 21/50



5/5 [==============================] - ETA: 0s - loss: 0.4723 - accuracy: 0.5091
Epoch 21: loss did not improve from 0.46529
5/5 [==============================] - 33s 7s/step - loss: 0.4723 - accuracy: 0.5091
Epoch 22/50



5/5 [==============================] - ETA: 0s - loss: 0.5304 - accuracy: 0.5734
Epoch 22: loss did not improve from 0.46529
5/5 [==============================] - 35s 7s/step - loss: 0.5304 - accuracy: 0.5734
Epoch 23/50



5/5 [==============================] - ETA: 0s - loss: 0.5191 - accuracy: 0.5703
Epoch 23: loss did not improve from 0.46529
5/5 [==============================] - 35s 7s/step - loss: 0.5191 - accuracy: 0.5703
Epoch 24/50



5/5 [==============================] - ETA: 0s - loss: 0.5127 - accuracy: 0.5072
Epoch 24: loss did not improve from 0.46529
5/5 [==============================] - 35s 7s/step - loss: 0.5127 - accuracy: 0.5072
Epoch 25/50



5/5 [==============================] - ETA: 0s - loss: 0.4990 - accuracy: 0.4445
Epoch 25: loss did not improve from 0.46529
5/5 [==============================] - 34s 7s/step - loss: 0.4990 - accuracy: 0.4445
Epoch 26/50



5/5 [==============================] - ETA: 0s - loss: 0.4873 - accuracy: 0.4738
Epoch 26: loss did not improve from 0.46529
5/5 [==============================] - 34s 7s/step - loss: 0.4873 - accuracy: 0.4738
Epoch 27/50



5/5 [==============================] - ETA: 0s - loss: 0.5139 - accuracy: 0.5025
Epoch 27: loss did not improve from 0.46529
5/5 [==============================] - 34s 7s/step - loss: 0.5139 - accuracy: 0.5025
Epoch 28/50



5/5 [==============================] - ETA: 0s - loss: 0.4869 - accuracy: 0.5140
Epoch 28: loss did not improve from 0.46529
5/5 [==============================] - 34s 7s/step - loss: 0.4869 - accuracy: 0.5140
Epoch 29/50



5/5 [==============================] - ETA: 0s - loss: 0.4990 - accuracy: 0.5190
Epoch 29: loss did not improve from 0.46529
5/5 [==============================] - 33s 7s/step - loss: 0.4990 - accuracy: 0.5190
Epoch 30/50



5/5 [==============================] - ETA: 0s - loss: 0.5809 - accuracy: 0.5076
Epoch 30: loss did not improve from 0.46529
5/5 [==============================] - 34s 7s/step - loss: 0.5809 - accuracy: 0.5076
Epoch 31/50



5/5 [==============================] - ETA: 0s - loss: 0.5139 - accuracy: 0.5522
Epoch 31: loss did not improve from 0.46529
5/5 [==============================] - 33s 7s/step - loss: 0.5139 - accuracy: 0.5522
Epoch 32/50



5/5 [==============================] - ETA: 0s - loss: 0.4748 - accuracy: 0.5103
Epoch 32: loss did not improve from 0.46529
5/5 [==============================] - 34s 7s/step - loss: 0.4748 - accuracy: 0.5103
Epoch 33/50



5/5 [==============================] - ETA: 0s - loss: 0.5482 - accuracy: 0.4148
Epoch 33: loss did not improve from 0.46529
5/5 [==============================] - 32s 7s/step - loss: 0.5482 - accuracy: 0.4148
Epoch 34/50



5/5 [==============================] - ETA: 0s - loss: 0.5559 - accuracy: 0.4795
Epoch 34: loss did not improve from 0.46529
5/5 [==============================] - 33s 7s/step - loss: 0.5559 - accuracy: 0.4795
Epoch 35/50



5/5 [==============================] - ETA: 0s - loss: 0.4643 - accuracy: 0.5599
Epoch 35: loss improved from 0.46529 to 0.46431, saving model to ckpt/suimnet_rsb_n2.hdf5
5/5 [==============================] - 41s 8s/step - loss: 0.4643 - accuracy: 0.5599
Epoch 36/50



5/5 [==============================] - ETA: 0s - loss: 0.4881 - accuracy: 0.5860
Epoch 36: loss did not improve from 0.46431
5/5 [==============================] - 28s 7s/step - loss: 0.4881 - accuracy: 0.5860
Epoch 37/50



5/5 [==============================] - ETA: 0s - loss: 0.4761 - accuracy: 0.4931
Epoch 37: loss did not improve from 0.46431
5/5 [==============================] - 33s 7s/step - loss: 0.4761 - accuracy: 0.4931
Epoch 38/50



5/5 [==============================] - ETA: 0s - loss: 0.5851 - accuracy: 0.4756
Epoch 38: loss did not improve from 0.46431
5/5 [==============================] - 35s 7s/step - loss: 0.5851 - accuracy: 0.4756
Epoch 39/50


5/5 [==============================] - ETA: 0s - loss: 0.5476 - accuracy: 0.5143
Epoch 39: loss did not improve from 0.46431
5/5 [==============================] - 32s 5s/step - loss: 0.5476 - accuracy: 0.5143
Epoch 40/50



5/5 [==============================] - ETA: 0s - loss: 0.5028 - accuracy: 0.4978
Epoch 40: loss did not improve from 0.46431
5/5 [==============================] - 35s 7s/step - loss: 0.5028 - accuracy: 0.4978
Epoch 41/50



5/5 [==============================] - ETA: 0s - loss: 0.4822 - accuracy: 0.5696
Epoch 41: loss did not improve from 0.46431
5/5 [==============================] - 34s 7s/step - loss: 0.4822 - accuracy: 0.5696
Epoch 42/50




5/5 [==============================] - ETA: 0s - loss: 0.5342 - accuracy: 0.5556
Epoch 42: loss did not improve from 0.46431
5/5 [==============================] - 33s 7s/step - loss: 0.5342 - accuracy: 0.5556
Epoch 43/50



5/5 [==============================] - ETA: 0s - loss: 0.4842 - accuracy: 0.5476
Epoch 43: loss did not improve from 0.46431
5/5 [==============================] - 34s 7s/step - loss: 0.4842 - accuracy: 0.5476
Epoch 44/50



5/5 [==============================] - ETA: 0s - loss: 0.4620 - accuracy: 0.4507
Epoch 44: loss improved from 0.46431 to 0.46205, saving model to ckpt/suimnet_rsb_n2.hdf5
5/5 [==============================] - 42s 9s/step - loss: 0.4620 - accuracy: 0.4507
Epoch 45/50



5/5 [==============================] - ETA: 0s - loss: 0.4349 - accuracy: 0.4476
Epoch 45: loss improved from 0.46205 to 0.43487, saving model to ckpt/suimnet_rsb_n2.hdf5
5/5 [==============================] - 34s 8s/step - loss: 0.4349 - accuracy: 0.4476
Epoch 46/50



5/5 [==============================] - ETA: 0s - loss: 0.5330 - accuracy: 0.5177
Epoch 46: loss did not improve from 0.43487
5/5 [==============================] - 28s 7s/step - loss: 0.5330 - accuracy: 0.5177
Epoch 47/50



5/5 [==============================] - ETA: 0s - loss: 0.4484 - accuracy: 0.5820
Epoch 47: loss did not improve from 0.43487
5/5 [==============================] - 34s 7s/step - loss: 0.4484 - accuracy: 0.5820
Epoch 48/50



5/5 [==============================] - ETA: 0s - loss: 0.4505 - accuracy: 0.5473
Epoch 48: loss did not improve from 0.43487
5/5 [==============================] - 34s 7s/step - loss: 0.4505 - accuracy: 0.5473
Epoch 49/50



5/5 [==============================] - ETA: 0s - loss: 0.4675 - accuracy: 0.4768
Epoch 49: loss did not improve from 0.43487
5/5 [==============================] - 34s 7s/step - loss: 0.4675 - accuracy: 0.4768
Epoch 50/50



5/5 [==============================] - ETA: 0s - loss: 0.5052 - accuracy: 0.5280
Epoch 50: loss did not improve from 0.43487
5/5 [==============================] - 34s 7s/step - loss: 0.5052 - accuracy: 0.5280