RSB
(320, 240, 3)
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to
==================================================================================================
 input_1 (InputLayer)           [(None, 240, 320, 3  0           []
                                )]
 conv2d (Conv2D)                (None, 236, 316, 64  4864        ['input_1[0][0]']
                                )
 batch_normalization (BatchNorm  (None, 236, 316, 64  256        ['conv2d[0][0]']
 alization)                     )
 activation (Activation)        (None, 236, 316, 64  0           ['batch_normalization[0][0]']
                                )
 max_pooling2d (MaxPooling2D)   (None, 117, 157, 64  0           ['activation[0][0]']
                                )
 conv2d_1 (Conv2D)              (None, 59, 79, 64)   4160        ['max_pooling2d[0][0]']
 batch_normalization_1 (BatchNo  (None, 59, 79, 64)  256         ['conv2d_1[0][0]']
 rmalization)
 activation_1 (Activation)      (None, 59, 79, 64)   0           ['batch_normalization_1[0][0]']
 conv2d_2 (Conv2D)              (None, 59, 79, 64)   36928       ['activation_1[0][0]']
 batch_normalization_2 (BatchNo  (None, 59, 79, 64)  256         ['conv2d_2[0][0]']
 rmalization)
 activation_2 (Activation)      (None, 59, 79, 64)   0           ['batch_normalization_2[0][0]']
 conv2d_3 (Conv2D)              (None, 59, 79, 128)  8320        ['activation_2[0][0]']
 conv2d_4 (Conv2D)              (None, 59, 79, 128)  8320        ['max_pooling2d[0][0]']
 batch_normalization_3 (BatchNo  (None, 59, 79, 128)  512        ['conv2d_3[0][0]']
 rmalization)
 batch_normalization_4 (BatchNo  (None, 59, 79, 128)  512        ['conv2d_4[0][0]']
 rmalization)
 add (Add)                      (None, 59, 79, 128)  0           ['batch_normalization_3[0][0]',
                                                                  'batch_normalization_4[0][0]']
 activation_3 (Activation)      (None, 59, 79, 128)  0           ['add[0][0]']
 conv2d_5 (Conv2D)              (None, 59, 79, 64)   8256        ['activation_3[0][0]']
 batch_normalization_5 (BatchNo  (None, 59, 79, 64)  256         ['conv2d_5[0][0]']
 rmalization)
 activation_4 (Activation)      (None, 59, 79, 64)   0           ['batch_normalization_5[0][0]']
 conv2d_6 (Conv2D)              (None, 59, 79, 64)   36928       ['activation_4[0][0]']
 batch_normalization_6 (BatchNo  (None, 59, 79, 64)  256         ['conv2d_6[0][0]']
 rmalization)
 activation_5 (Activation)      (None, 59, 79, 64)   0           ['batch_normalization_6[0][0]']
 conv2d_7 (Conv2D)              (None, 59, 79, 128)  8320        ['activation_5[0][0]']
 batch_normalization_7 (BatchNo  (None, 59, 79, 128)  512        ['conv2d_7[0][0]']
 rmalization)
 add_1 (Add)                    (None, 59, 79, 128)  0           ['batch_normalization_7[0][0]',
                                                                  'activation_3[0][0]']
 activation_6 (Activation)      (None, 59, 79, 128)  0           ['add_1[0][0]']
 conv2d_8 (Conv2D)              (None, 59, 79, 64)   8256        ['activation_6[0][0]']
 batch_normalization_8 (BatchNo  (None, 59, 79, 64)  256         ['conv2d_8[0][0]']
 rmalization)
 activation_7 (Activation)      (None, 59, 79, 64)   0           ['batch_normalization_8[0][0]']
 conv2d_9 (Conv2D)              (None, 59, 79, 64)   36928       ['activation_7[0][0]']
 batch_normalization_9 (BatchNo  (None, 59, 79, 64)  256         ['conv2d_9[0][0]']
 rmalization)
 activation_8 (Activation)      (None, 59, 79, 64)   0           ['batch_normalization_9[0][0]']
 conv2d_10 (Conv2D)             (None, 59, 79, 128)  8320        ['activation_8[0][0]']
 batch_normalization_10 (BatchN  (None, 59, 79, 128)  512        ['conv2d_10[0][0]']
 ormalization)
 add_2 (Add)                    (None, 59, 79, 128)  0           ['batch_normalization_10[0][0]',
                                                                  'activation_6[0][0]']
 activation_9 (Activation)      (None, 59, 79, 128)  0           ['add_2[0][0]']
 conv2d_11 (Conv2D)             (None, 30, 40, 128)  16512       ['activation_9[0][0]']
 batch_normalization_11 (BatchN  (None, 30, 40, 128)  512        ['conv2d_11[0][0]']
 ormalization)
 activation_10 (Activation)     (None, 30, 40, 128)  0           ['batch_normalization_11[0][0]']
 conv2d_12 (Conv2D)             (None, 30, 40, 128)  147584      ['activation_10[0][0]']
 batch_normalization_12 (BatchN  (None, 30, 40, 128)  512        ['conv2d_12[0][0]']
 ormalization)
 activation_11 (Activation)     (None, 30, 40, 128)  0           ['batch_normalization_12[0][0]']
 conv2d_13 (Conv2D)             (None, 30, 40, 256)  33024       ['activation_11[0][0]']
 conv2d_14 (Conv2D)             (None, 30, 40, 256)  33024       ['activation_9[0][0]']
 batch_normalization_13 (BatchN  (None, 30, 40, 256)  1024       ['conv2d_13[0][0]']
 ormalization)
 batch_normalization_14 (BatchN  (None, 30, 40, 256)  1024       ['conv2d_14[0][0]']
 ormalization)
 add_3 (Add)                    (None, 30, 40, 256)  0           ['batch_normalization_13[0][0]',
                                                                  'batch_normalization_14[0][0]']
 activation_12 (Activation)     (None, 30, 40, 256)  0           ['add_3[0][0]']
 conv2d_15 (Conv2D)             (None, 30, 40, 128)  32896       ['activation_12[0][0]']
 batch_normalization_15 (BatchN  (None, 30, 40, 128)  512        ['conv2d_15[0][0]']
 ormalization)
 activation_13 (Activation)     (None, 30, 40, 128)  0           ['batch_normalization_15[0][0]']
 conv2d_16 (Conv2D)             (None, 30, 40, 128)  147584      ['activation_13[0][0]']
 batch_normalization_16 (BatchN  (None, 30, 40, 128)  512        ['conv2d_16[0][0]']
 ormalization)
 activation_14 (Activation)     (None, 30, 40, 128)  0           ['batch_normalization_16[0][0]']
 conv2d_17 (Conv2D)             (None, 30, 40, 256)  33024       ['activation_14[0][0]']
 batch_normalization_17 (BatchN  (None, 30, 40, 256)  1024       ['conv2d_17[0][0]']
 ormalization)
 add_4 (Add)                    (None, 30, 40, 256)  0           ['batch_normalization_17[0][0]',
                                                                  'activation_12[0][0]']
 activation_15 (Activation)     (None, 30, 40, 256)  0           ['add_4[0][0]']
 conv2d_18 (Conv2D)             (None, 30, 40, 128)  32896       ['activation_15[0][0]']
 batch_normalization_18 (BatchN  (None, 30, 40, 128)  512        ['conv2d_18[0][0]']
 ormalization)
 activation_16 (Activation)     (None, 30, 40, 128)  0           ['batch_normalization_18[0][0]']
 conv2d_19 (Conv2D)             (None, 30, 40, 128)  147584      ['activation_16[0][0]']
 batch_normalization_19 (BatchN  (None, 30, 40, 128)  512        ['conv2d_19[0][0]']
 ormalization)
 activation_17 (Activation)     (None, 30, 40, 128)  0           ['batch_normalization_19[0][0]']
 conv2d_20 (Conv2D)             (None, 30, 40, 256)  33024       ['activation_17[0][0]']
 batch_normalization_20 (BatchN  (None, 30, 40, 256)  1024       ['conv2d_20[0][0]']
 ormalization)
 add_5 (Add)                    (None, 30, 40, 256)  0           ['batch_normalization_20[0][0]',
                                                                  'activation_15[0][0]']
 activation_18 (Activation)     (None, 30, 40, 256)  0           ['add_5[0][0]']
 conv2d_21 (Conv2D)             (None, 30, 40, 128)  32896       ['activation_18[0][0]']
 batch_normalization_21 (BatchN  (None, 30, 40, 128)  512        ['conv2d_21[0][0]']
 ormalization)
 activation_19 (Activation)     (None, 30, 40, 128)  0           ['batch_normalization_21[0][0]']
 conv2d_22 (Conv2D)             (None, 30, 40, 128)  147584      ['activation_19[0][0]']
 batch_normalization_22 (BatchN  (None, 30, 40, 128)  512        ['conv2d_22[0][0]']
 ormalization)
 activation_20 (Activation)     (None, 30, 40, 128)  0           ['batch_normalization_22[0][0]']
 conv2d_23 (Conv2D)             (None, 30, 40, 256)  33024       ['activation_20[0][0]']
 batch_normalization_23 (BatchN  (None, 30, 40, 256)  1024       ['conv2d_23[0][0]']
 ormalization)
 add_6 (Add)                    (None, 30, 40, 256)  0           ['batch_normalization_23[0][0]',
                                                                  'activation_18[0][0]']
 activation_21 (Activation)     (None, 30, 40, 256)  0           ['add_6[0][0]']
 conv2d_24 (Conv2D)             (None, 30, 40, 256)  590080      ['activation_21[0][0]']
 lambda_1 (Lambda)              (None, 58, 78, 128)  0           ['activation_9[0][0]']
 batch_normalization_24 (BatchN  (None, 30, 40, 256)  1024       ['conv2d_24[0][0]']
 ormalization)
 zero_padding2d_1 (ZeroPadding2  (None, 60, 80, 128)  0          ['lambda_1[0][0]']
 D)
 up_sampling2d (UpSampling2D)   (None, 60, 80, 256)  0           ['batch_normalization_24[0][0]']
 conv2d_25 (Conv2D)             (None, 60, 80, 256)  295168      ['zero_padding2d_1[0][0]']
 lambda (Lambda)                (None, 58, 78, 256)  0           ['up_sampling2d[0][0]']
 batch_normalization_25 (BatchN  (None, 60, 80, 256)  1024       ['conv2d_25[0][0]']
 ormalization)
 zero_padding2d (ZeroPadding2D)  (None, 60, 80, 256)  0          ['lambda[0][0]']
 concatenate (Concatenate)      (None, 60, 80, 512)  0           ['batch_normalization_25[0][0]',
                                                                  'zero_padding2d[0][0]']
 conv2d_26 (Conv2D)             (None, 60, 80, 256)  1179904     ['concatenate[0][0]']
 batch_normalization_26 (BatchN  (None, 60, 80, 256)  1024       ['conv2d_26[0][0]']
 ormalization)
 up_sampling2d_1 (UpSampling2D)  (None, 120, 160, 25  0          ['batch_normalization_26[0][0]']
                                6)
 zero_padding2d_2 (ZeroPadding2  (None, 240, 320, 64  0          ['conv2d[0][0]']
 D)                             )
 conv2d_27 (Conv2D)             (None, 120, 160, 12  295040      ['up_sampling2d_1[0][0]']
                                8)
 conv2d_28 (Conv2D)             (None, 240, 320, 12  73856       ['zero_padding2d_2[0][0]']
                                8)
 batch_normalization_27 (BatchN  (None, 120, 160, 12  512        ['conv2d_27[0][0]']
 ormalization)                  8)
 batch_normalization_28 (BatchN  (None, 240, 320, 12  512        ['conv2d_28[0][0]']
 ormalization)                  8)
 up_sampling2d_2 (UpSampling2D)  (None, 240, 320, 12  0          ['batch_normalization_27[0][0]']
                                8)
 concatenate_1 (Concatenate)    (None, 240, 320, 25  0           ['batch_normalization_28[0][0]',
                                6)                                'up_sampling2d_2[0][0]']
 conv2d_29 (Conv2D)             (None, 240, 320, 12  295040      ['concatenate_1[0][0]']
                                8)
 batch_normalization_29 (BatchN  (None, 240, 320, 12  512        ['conv2d_29[0][0]']
 ormalization)                  8)
 conv2d_30 (Conv2D)             (None, 240, 320, 64  73792       ['batch_normalization_29[0][0]']
                                )
 batch_normalization_30 (BatchN  (None, 240, 320, 64  256        ['conv2d_30[0][0]']
 ormalization)                  )
 conv2d_31 (Conv2D)             (None, 240, 320, 2)  1154        ['batch_normalization_30[0][0]']
==================================================================================================
Total params: 3,862,210
Trainable params: 3,853,250
Non-trainable params: 8,960
__________________________________________________________________________________________________
None
Found 1525 images belonging to 1 classes.
Found 1525 images belonging to 1 classes.
Epoch 1/50


5/5 [==============================] - ETA: 0s - loss: 0.7315 - accuracy: 0.4457
Epoch 1: loss improved from inf to 0.73151, saving model to ckpt/suimnet_rsb_n2.hdf5
5/5 [==============================] - 39s 7s/step - loss: 0.7315 - accuracy: 0.4457
Epoch 2/50



5/5 [==============================] - ETA: 0s - loss: 0.6707 - accuracy: 0.5550
Epoch 2: loss improved from 0.73151 to 0.67066, saving model to ckpt/suimnet_rsb_n2.hdf5
5/5 [==============================] - 34s 8s/step - loss: 0.6707 - accuracy: 0.5550
Epoch 3/50



5/5 [==============================] - ETA: 0s - loss: 0.4454 - accuracy: 0.5549
Epoch 3: loss improved from 0.67066 to 0.44537, saving model to ckpt/suimnet_rsb_n2.hdf5
5/5 [==============================] - 35s 9s/step - loss: 0.4454 - accuracy: 0.5549
Epoch 4/50



5/5 [==============================] - ETA: 0s - loss: 0.4743 - accuracy: 0.5933
Epoch 4: loss did not improve from 0.44537
5/5 [==============================] - 28s 7s/step - loss: 0.4743 - accuracy: 0.5933
Epoch 5/50



5/5 [==============================] - ETA: 0s - loss: 0.6255 - accuracy: 0.5438
Epoch 5: loss did not improve from 0.44537
5/5 [==============================] - 34s 7s/step - loss: 0.6255 - accuracy: 0.5438
Epoch 6/50



5/5 [==============================] - ETA: 0s - loss: 0.5786 - accuracy: 0.5906
Epoch 6: loss did not improve from 0.44537
5/5 [==============================] - 35s 7s/step - loss: 0.5786 - accuracy: 0.5906
Epoch 7/50



5/5 [==============================] - ETA: 0s - loss: 0.5581 - accuracy: 0.5517
Epoch 7: loss did not improve from 0.44537
5/5 [==============================] - 34s 7s/step - loss: 0.5581 - accuracy: 0.5517
Epoch 8/50



5/5 [==============================] - ETA: 0s - loss: 0.5739 - accuracy: 0.6610
Epoch 8: loss did not improve from 0.44537
5/5 [==============================] - 34s 7s/step - loss: 0.5739 - accuracy: 0.6610
Epoch 9/50



5/5 [==============================] - ETA: 0s - loss: 0.5780 - accuracy: 0.5641
Epoch 9: loss did not improve from 0.44537
5/5 [==============================] - 34s 7s/step - loss: 0.5780 - accuracy: 0.5641
Epoch 10/50



5/5 [==============================] - ETA: 0s - loss: 0.5305 - accuracy: 0.5607
Epoch 10: loss did not improve from 0.44537
5/5 [==============================] - 34s 7s/step - loss: 0.5305 - accuracy: 0.5607
Epoch 11/50



5/5 [==============================] - ETA: 0s - loss: 0.4540 - accuracy: 0.6404
Epoch 11: loss did not improve from 0.44537
5/5 [==============================] - 36s 7s/step - loss: 0.4540 - accuracy: 0.6404
Epoch 12/50



5/5 [==============================] - ETA: 0s - loss: 0.5549 - accuracy: 0.5726
Epoch 12: loss did not improve from 0.44537
5/5 [==============================] - 34s 7s/step - loss: 0.5549 - accuracy: 0.5726
Epoch 13/50



5/5 [==============================] - ETA: 0s - loss: 0.5399 - accuracy: 0.4357
Epoch 13: loss did not improve from 0.44537
5/5 [==============================] - 33s 7s/step - loss: 0.5399 - accuracy: 0.4357
Epoch 14/50



5/5 [==============================] - ETA: 0s - loss: 0.5978 - accuracy: 0.4571
Epoch 14: loss did not improve from 0.44537
5/5 [==============================] - 34s 7s/step - loss: 0.5978 - accuracy: 0.4571
Epoch 15/50



5/5 [==============================] - ETA: 0s - loss: 0.5971 - accuracy: 0.6002
Epoch 15: loss did not improve from 0.44537
5/5 [==============================] - 34s 7s/step - loss: 0.5971 - accuracy: 0.6002
Epoch 16/50



5/5 [==============================] - ETA: 0s - loss: 0.5497 - accuracy: 0.5834
Epoch 16: loss did not improve from 0.44537
5/5 [==============================] - 34s 7s/step - loss: 0.5497 - accuracy: 0.5834
Epoch 17/50



5/5 [==============================] - ETA: 0s - loss: 0.5385 - accuracy: 0.5582
Epoch 17: loss did not improve from 0.44537
5/5 [==============================] - 33s 7s/step - loss: 0.5385 - accuracy: 0.5582
Epoch 18/50



5/5 [==============================] - ETA: 0s - loss: 0.4881 - accuracy: 0.5708
Epoch 18: loss did not improve from 0.44537
5/5 [==============================] - 33s 7s/step - loss: 0.4881 - accuracy: 0.5708
Epoch 19/50



5/5 [==============================] - ETA: 0s - loss: 0.5915 - accuracy: 0.5154
Epoch 19: loss did not improve from 0.44537
5/5 [==============================] - 34s 7s/step - loss: 0.5915 - accuracy: 0.5154
Epoch 20/50



5/5 [==============================] - ETA: 0s - loss: 0.4936 - accuracy: 0.4802
Epoch 20: loss did not improve from 0.44537
5/5 [==============================] - 35s 7s/step - loss: 0.4936 - accuracy: 0.4802
Epoch 21/50



5/5 [==============================] - ETA: 0s - loss: 0.5469 - accuracy: 0.5376
Epoch 21: loss did not improve from 0.44537
5/5 [==============================] - 33s 7s/step - loss: 0.5469 - accuracy: 0.5376
Epoch 22/50



5/5 [==============================] - ETA: 0s - loss: 0.5714 - accuracy: 0.4997
Epoch 22: loss did not improve from 0.44537
5/5 [==============================] - 34s 7s/step - loss: 0.5714 - accuracy: 0.4997
Epoch 23/50



5/5 [==============================] - ETA: 0s - loss: 0.5415 - accuracy: 0.5756
Epoch 23: loss did not improve from 0.44537
5/5 [==============================] - 35s 7s/step - loss: 0.5415 - accuracy: 0.5756
Epoch 24/50



5/5 [==============================] - ETA: 0s - loss: 0.5358 - accuracy: 0.6532
Epoch 24: loss did not improve from 0.44537
5/5 [==============================] - 35s 7s/step - loss: 0.5358 - accuracy: 0.6532
Epoch 25/50



5/5 [==============================] - ETA: 0s - loss: 0.5063 - accuracy: 0.5320
Epoch 25: loss did not improve from 0.44537
5/5 [==============================] - 34s 7s/step - loss: 0.5063 - accuracy: 0.5320
Epoch 26/50



5/5 [==============================] - ETA: 0s - loss: 0.5076 - accuracy: 0.5416
Epoch 26: loss did not improve from 0.44537
5/5 [==============================] - 34s 7s/step - loss: 0.5076 - accuracy: 0.5416
Epoch 27/50



5/5 [==============================] - ETA: 0s - loss: 0.5192 - accuracy: 0.6190
Epoch 27: loss did not improve from 0.44537
5/5 [==============================] - 34s 7s/step - loss: 0.5192 - accuracy: 0.6190
Epoch 28/50



5/5 [==============================] - ETA: 0s - loss: 0.4875 - accuracy: 0.5623
Epoch 28: loss did not improve from 0.44537
5/5 [==============================] - 34s 7s/step - loss: 0.4875 - accuracy: 0.5623
Epoch 29/50



5/5 [==============================] - ETA: 0s - loss: 0.4943 - accuracy: 0.3856
Epoch 29: loss did not improve from 0.44537
5/5 [==============================] - 33s 7s/step - loss: 0.4943 - accuracy: 0.3856
Epoch 30/50



5/5 [==============================] - ETA: 0s - loss: 0.5829 - accuracy: 0.4307
Epoch 30: loss did not improve from 0.44537
5/5 [==============================] - 34s 7s/step - loss: 0.5829 - accuracy: 0.4307
Epoch 31/50



5/5 [==============================] - ETA: 0s - loss: 0.5637 - accuracy: 0.5918
Epoch 31: loss did not improve from 0.44537
5/5 [==============================] - 33s 7s/step - loss: 0.5637 - accuracy: 0.5918
Epoch 32/50



5/5 [==============================] - ETA: 0s - loss: 0.5001 - accuracy: 0.5910
Epoch 32: loss did not improve from 0.44537
5/5 [==============================] - 34s 7s/step - loss: 0.5001 - accuracy: 0.5910
Epoch 33/50




5/5 [==============================] - ETA: 0s - loss: 0.5706 - accuracy: 0.5200
Epoch 33: loss did not improve from 0.44537
5/5 [==============================] - 32s 7s/step - loss: 0.5706 - accuracy: 0.5200
Epoch 34/50



5/5 [==============================] - ETA: 0s - loss: 0.6219 - accuracy: 0.4725
Epoch 34: loss did not improve from 0.44537
5/5 [==============================] - 33s 7s/step - loss: 0.6219 - accuracy: 0.4725
Epoch 35/50



5/5 [==============================] - ETA: 0s - loss: 0.5104 - accuracy: 0.5676
Epoch 35: loss did not improve from 0.44537
5/5 [==============================] - 34s 7s/step - loss: 0.5104 - accuracy: 0.5676
Epoch 36/50



5/5 [==============================] - ETA: 0s - loss: 0.5450 - accuracy: 0.4958
Epoch 36: loss did not improve from 0.44537
5/5 [==============================] - 34s 7s/step - loss: 0.5450 - accuracy: 0.4958
Epoch 37/50



5/5 [==============================] - ETA: 0s - loss: 0.6330 - accuracy: 0.4587
Epoch 37: loss did not improve from 0.44537
5/5 [==============================] - 33s 7s/step - loss: 0.6330 - accuracy: 0.4587
Epoch 38/50



5/5 [==============================] - ETA: 0s - loss: 0.6022 - accuracy: 0.5287
Epoch 38: loss did not improve from 0.44537
5/5 [==============================] - 35s 7s/step - loss: 0.6022 - accuracy: 0.5287
Epoch 39/50


5/5 [==============================] - ETA: 0s - loss: 0.6268 - accuracy: 0.4984
Epoch 39: loss did not improve from 0.44537
5/5 [==============================] - 31s 5s/step - loss: 0.6268 - accuracy: 0.4984
Epoch 40/50



5/5 [==============================] - ETA: 0s - loss: 0.6168 - accuracy: 0.4796
Epoch 40: loss did not improve from 0.44537
5/5 [==============================] - 34s 7s/step - loss: 0.6168 - accuracy: 0.4796
Epoch 41/50



5/5 [==============================] - ETA: 0s - loss: 0.5250 - accuracy: 0.4836
Epoch 41: loss did not improve from 0.44537
5/5 [==============================] - 34s 7s/step - loss: 0.5250 - accuracy: 0.4836
Epoch 42/50



5/5 [==============================] - ETA: 0s - loss: 0.5529 - accuracy: 0.4960
Epoch 42: loss did not improve from 0.44537
5/5 [==============================] - 33s 7s/step - loss: 0.5529 - accuracy: 0.4960
Epoch 43/50



5/5 [==============================] - ETA: 0s - loss: 0.5192 - accuracy: 0.5609
Epoch 43: loss did not improve from 0.44537
5/5 [==============================] - 34s 7s/step - loss: 0.5192 - accuracy: 0.5609
Epoch 44/50



5/5 [==============================] - ETA: 0s - loss: 0.5138 - accuracy: 0.5411
Epoch 44: loss did not improve from 0.44537
5/5 [==============================] - 35s 7s/step - loss: 0.5138 - accuracy: 0.5411
Epoch 45/50



5/5 [==============================] - ETA: 0s - loss: 0.4638 - accuracy: 0.4313
Epoch 45: loss did not improve from 0.44537
5/5 [==============================] - 34s 7s/step - loss: 0.4638 - accuracy: 0.4313
Epoch 46/50



5/5 [==============================] - ETA: 0s - loss: 0.5419 - accuracy: 0.5277
Epoch 46: loss did not improve from 0.44537
5/5 [==============================] - 35s 7s/step - loss: 0.5419 - accuracy: 0.5277
Epoch 47/50



5/5 [==============================] - ETA: 0s - loss: 0.4976 - accuracy: 0.4520
Epoch 47: loss did not improve from 0.44537
5/5 [==============================] - 34s 7s/step - loss: 0.4976 - accuracy: 0.4520
Epoch 48/50



5/5 [==============================] - ETA: 0s - loss: 0.4867 - accuracy: 0.6042
Epoch 48: loss did not improve from 0.44537
5/5 [==============================] - 34s 7s/step - loss: 0.4867 - accuracy: 0.6042
Epoch 49/50



5/5 [==============================] - ETA: 0s - loss: 0.5188 - accuracy: 0.4386
Epoch 49: loss did not improve from 0.44537
5/5 [==============================] - 34s 7s/step - loss: 0.5188 - accuracy: 0.4386
Epoch 50/50




5/5 [==============================] - ETA: 0s - loss: 0.5372 - accuracy: 0.4065
Epoch 50: loss did not improve from 0.44537
5/5 [==============================] - 34s 7s/step - loss: 0.5372 - accuracy: 0.4065