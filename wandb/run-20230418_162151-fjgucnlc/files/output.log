RSB
(320, 240, 3)
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to
==================================================================================================
 input_1 (InputLayer)           [(None, 240, 320, 3  0           []
                                )]
 conv2d (Conv2D)                (None, 236, 316, 64  4864        ['input_1[0][0]']
                                )
 batch_normalization (BatchNorm  (None, 236, 316, 64  256        ['conv2d[0][0]']
 alization)                     )
 activation (Activation)        (None, 236, 316, 64  0           ['batch_normalization[0][0]']
                                )
 max_pooling2d (MaxPooling2D)   (None, 117, 157, 64  0           ['activation[0][0]']
                                )
 conv2d_1 (Conv2D)              (None, 59, 79, 64)   4160        ['max_pooling2d[0][0]']
 batch_normalization_1 (BatchNo  (None, 59, 79, 64)  256         ['conv2d_1[0][0]']
 rmalization)
 activation_1 (Activation)      (None, 59, 79, 64)   0           ['batch_normalization_1[0][0]']
 conv2d_2 (Conv2D)              (None, 59, 79, 64)   36928       ['activation_1[0][0]']
 batch_normalization_2 (BatchNo  (None, 59, 79, 64)  256         ['conv2d_2[0][0]']
 rmalization)
 activation_2 (Activation)      (None, 59, 79, 64)   0           ['batch_normalization_2[0][0]']
 conv2d_3 (Conv2D)              (None, 59, 79, 128)  8320        ['activation_2[0][0]']
 conv2d_4 (Conv2D)              (None, 59, 79, 128)  8320        ['max_pooling2d[0][0]']
 batch_normalization_3 (BatchNo  (None, 59, 79, 128)  512        ['conv2d_3[0][0]']
 rmalization)
 batch_normalization_4 (BatchNo  (None, 59, 79, 128)  512        ['conv2d_4[0][0]']
 rmalization)
 add (Add)                      (None, 59, 79, 128)  0           ['batch_normalization_3[0][0]',
                                                                  'batch_normalization_4[0][0]']
 activation_3 (Activation)      (None, 59, 79, 128)  0           ['add[0][0]']
 conv2d_5 (Conv2D)              (None, 59, 79, 64)   8256        ['activation_3[0][0]']
 batch_normalization_5 (BatchNo  (None, 59, 79, 64)  256         ['conv2d_5[0][0]']
 rmalization)
 activation_4 (Activation)      (None, 59, 79, 64)   0           ['batch_normalization_5[0][0]']
 conv2d_6 (Conv2D)              (None, 59, 79, 64)   36928       ['activation_4[0][0]']
 batch_normalization_6 (BatchNo  (None, 59, 79, 64)  256         ['conv2d_6[0][0]']
 rmalization)
 activation_5 (Activation)      (None, 59, 79, 64)   0           ['batch_normalization_6[0][0]']
 conv2d_7 (Conv2D)              (None, 59, 79, 128)  8320        ['activation_5[0][0]']
 batch_normalization_7 (BatchNo  (None, 59, 79, 128)  512        ['conv2d_7[0][0]']
 rmalization)
 add_1 (Add)                    (None, 59, 79, 128)  0           ['batch_normalization_7[0][0]',
                                                                  'activation_3[0][0]']
 activation_6 (Activation)      (None, 59, 79, 128)  0           ['add_1[0][0]']
 conv2d_8 (Conv2D)              (None, 59, 79, 64)   8256        ['activation_6[0][0]']
 batch_normalization_8 (BatchNo  (None, 59, 79, 64)  256         ['conv2d_8[0][0]']
 rmalization)
 activation_7 (Activation)      (None, 59, 79, 64)   0           ['batch_normalization_8[0][0]']
 conv2d_9 (Conv2D)              (None, 59, 79, 64)   36928       ['activation_7[0][0]']
 batch_normalization_9 (BatchNo  (None, 59, 79, 64)  256         ['conv2d_9[0][0]']
 rmalization)
 activation_8 (Activation)      (None, 59, 79, 64)   0           ['batch_normalization_9[0][0]']
 conv2d_10 (Conv2D)             (None, 59, 79, 128)  8320        ['activation_8[0][0]']
 batch_normalization_10 (BatchN  (None, 59, 79, 128)  512        ['conv2d_10[0][0]']
 ormalization)
 add_2 (Add)                    (None, 59, 79, 128)  0           ['batch_normalization_10[0][0]',
                                                                  'activation_6[0][0]']
 activation_9 (Activation)      (None, 59, 79, 128)  0           ['add_2[0][0]']
 conv2d_11 (Conv2D)             (None, 30, 40, 128)  16512       ['activation_9[0][0]']
 batch_normalization_11 (BatchN  (None, 30, 40, 128)  512        ['conv2d_11[0][0]']
 ormalization)
 activation_10 (Activation)     (None, 30, 40, 128)  0           ['batch_normalization_11[0][0]']
 conv2d_12 (Conv2D)             (None, 30, 40, 128)  147584      ['activation_10[0][0]']
 batch_normalization_12 (BatchN  (None, 30, 40, 128)  512        ['conv2d_12[0][0]']
 ormalization)
 activation_11 (Activation)     (None, 30, 40, 128)  0           ['batch_normalization_12[0][0]']
 conv2d_13 (Conv2D)             (None, 30, 40, 256)  33024       ['activation_11[0][0]']
 conv2d_14 (Conv2D)             (None, 30, 40, 256)  33024       ['activation_9[0][0]']
 batch_normalization_13 (BatchN  (None, 30, 40, 256)  1024       ['conv2d_13[0][0]']
 ormalization)
 batch_normalization_14 (BatchN  (None, 30, 40, 256)  1024       ['conv2d_14[0][0]']
 ormalization)
 add_3 (Add)                    (None, 30, 40, 256)  0           ['batch_normalization_13[0][0]',
                                                                  'batch_normalization_14[0][0]']
 activation_12 (Activation)     (None, 30, 40, 256)  0           ['add_3[0][0]']
 conv2d_15 (Conv2D)             (None, 30, 40, 128)  32896       ['activation_12[0][0]']
 batch_normalization_15 (BatchN  (None, 30, 40, 128)  512        ['conv2d_15[0][0]']
 ormalization)
 activation_13 (Activation)     (None, 30, 40, 128)  0           ['batch_normalization_15[0][0]']
 conv2d_16 (Conv2D)             (None, 30, 40, 128)  147584      ['activation_13[0][0]']
 batch_normalization_16 (BatchN  (None, 30, 40, 128)  512        ['conv2d_16[0][0]']
 ormalization)
 activation_14 (Activation)     (None, 30, 40, 128)  0           ['batch_normalization_16[0][0]']
 conv2d_17 (Conv2D)             (None, 30, 40, 256)  33024       ['activation_14[0][0]']
 batch_normalization_17 (BatchN  (None, 30, 40, 256)  1024       ['conv2d_17[0][0]']
 ormalization)
 add_4 (Add)                    (None, 30, 40, 256)  0           ['batch_normalization_17[0][0]',
                                                                  'activation_12[0][0]']
 activation_15 (Activation)     (None, 30, 40, 256)  0           ['add_4[0][0]']
 conv2d_18 (Conv2D)             (None, 30, 40, 128)  32896       ['activation_15[0][0]']
 batch_normalization_18 (BatchN  (None, 30, 40, 128)  512        ['conv2d_18[0][0]']
 ormalization)
 activation_16 (Activation)     (None, 30, 40, 128)  0           ['batch_normalization_18[0][0]']
 conv2d_19 (Conv2D)             (None, 30, 40, 128)  147584      ['activation_16[0][0]']
 batch_normalization_19 (BatchN  (None, 30, 40, 128)  512        ['conv2d_19[0][0]']
 ormalization)
 activation_17 (Activation)     (None, 30, 40, 128)  0           ['batch_normalization_19[0][0]']
 conv2d_20 (Conv2D)             (None, 30, 40, 256)  33024       ['activation_17[0][0]']
 batch_normalization_20 (BatchN  (None, 30, 40, 256)  1024       ['conv2d_20[0][0]']
 ormalization)
 add_5 (Add)                    (None, 30, 40, 256)  0           ['batch_normalization_20[0][0]',
                                                                  'activation_15[0][0]']
 activation_18 (Activation)     (None, 30, 40, 256)  0           ['add_5[0][0]']
 conv2d_21 (Conv2D)             (None, 30, 40, 128)  32896       ['activation_18[0][0]']
 batch_normalization_21 (BatchN  (None, 30, 40, 128)  512        ['conv2d_21[0][0]']
 ormalization)
 activation_19 (Activation)     (None, 30, 40, 128)  0           ['batch_normalization_21[0][0]']
 conv2d_22 (Conv2D)             (None, 30, 40, 128)  147584      ['activation_19[0][0]']
 batch_normalization_22 (BatchN  (None, 30, 40, 128)  512        ['conv2d_22[0][0]']
 ormalization)
 activation_20 (Activation)     (None, 30, 40, 128)  0           ['batch_normalization_22[0][0]']
 conv2d_23 (Conv2D)             (None, 30, 40, 256)  33024       ['activation_20[0][0]']
 batch_normalization_23 (BatchN  (None, 30, 40, 256)  1024       ['conv2d_23[0][0]']
 ormalization)
 add_6 (Add)                    (None, 30, 40, 256)  0           ['batch_normalization_23[0][0]',
                                                                  'activation_18[0][0]']
 activation_21 (Activation)     (None, 30, 40, 256)  0           ['add_6[0][0]']
 conv2d_24 (Conv2D)             (None, 30, 40, 256)  590080      ['activation_21[0][0]']
 lambda_1 (Lambda)              (None, 58, 78, 128)  0           ['activation_9[0][0]']
 batch_normalization_24 (BatchN  (None, 30, 40, 256)  1024       ['conv2d_24[0][0]']
 ormalization)
 zero_padding2d_1 (ZeroPadding2  (None, 60, 80, 128)  0          ['lambda_1[0][0]']
 D)
 up_sampling2d (UpSampling2D)   (None, 60, 80, 256)  0           ['batch_normalization_24[0][0]']
 conv2d_25 (Conv2D)             (None, 60, 80, 256)  295168      ['zero_padding2d_1[0][0]']
 lambda (Lambda)                (None, 58, 78, 256)  0           ['up_sampling2d[0][0]']
 batch_normalization_25 (BatchN  (None, 60, 80, 256)  1024       ['conv2d_25[0][0]']
 ormalization)
 zero_padding2d (ZeroPadding2D)  (None, 60, 80, 256)  0          ['lambda[0][0]']
 concatenate (Concatenate)      (None, 60, 80, 512)  0           ['batch_normalization_25[0][0]',
                                                                  'zero_padding2d[0][0]']
 conv2d_26 (Conv2D)             (None, 60, 80, 256)  1179904     ['concatenate[0][0]']
 batch_normalization_26 (BatchN  (None, 60, 80, 256)  1024       ['conv2d_26[0][0]']
 ormalization)
 up_sampling2d_1 (UpSampling2D)  (None, 120, 160, 25  0          ['batch_normalization_26[0][0]']
                                6)
 zero_padding2d_2 (ZeroPadding2  (None, 240, 320, 64  0          ['conv2d[0][0]']
 D)                             )
 conv2d_27 (Conv2D)             (None, 120, 160, 12  295040      ['up_sampling2d_1[0][0]']
                                8)
 conv2d_28 (Conv2D)             (None, 240, 320, 12  73856       ['zero_padding2d_2[0][0]']
                                8)
 batch_normalization_27 (BatchN  (None, 120, 160, 12  512        ['conv2d_27[0][0]']
 ormalization)                  8)
 batch_normalization_28 (BatchN  (None, 240, 320, 12  512        ['conv2d_28[0][0]']
 ormalization)                  8)
 up_sampling2d_2 (UpSampling2D)  (None, 240, 320, 12  0          ['batch_normalization_27[0][0]']
                                8)
 concatenate_1 (Concatenate)    (None, 240, 320, 25  0           ['batch_normalization_28[0][0]',
                                6)                                'up_sampling2d_2[0][0]']
 conv2d_29 (Conv2D)             (None, 240, 320, 12  295040      ['concatenate_1[0][0]']
                                8)
 batch_normalization_29 (BatchN  (None, 240, 320, 12  512        ['conv2d_29[0][0]']
 ormalization)                  8)
 conv2d_30 (Conv2D)             (None, 240, 320, 64  73792       ['batch_normalization_29[0][0]']
                                )
 batch_normalization_30 (BatchN  (None, 240, 320, 64  256        ['conv2d_30[0][0]']
 ormalization)                  )
 conv2d_31 (Conv2D)             (None, 240, 320, 2)  1154        ['batch_normalization_30[0][0]']
==================================================================================================
Total params: 3,862,210
Trainable params: 3,853,250
Non-trainable params: 8,960
__________________________________________________________________________________________________
None
Found 1603 images belonging to 1 classes.
Found 1603 images belonging to 1 classes.
Epoch 1/20
1/1 [==============================] - ETA: 0s - loss: 0.2295 - accuracy: 0.4318
Epoch 1: loss improved from inf to 0.22952, saving model to ckpt/suimnet_img_logger.hdf5
Found 1603 images belonging to 1 classes.
Found 1603 images belonging to 1 classes.
1/1 [==============================] - 2s 2s/step
1/1 [==============================] - 23s 23s/step - loss: 0.2295 - accuracy: 0.4318
Epoch 2/20
1/1 [==============================] - ETA: 0s - loss: 0.6657 - accuracy: 0.4788
Epoch 2: loss did not improve from 0.22952
1/1 [==============================] - 2s 2s/step
1/1 [==============================] - 21s 21s/step - loss: 0.6657 - accuracy: 0.4788
Epoch 3/20
1/1 [==============================] - ETA: 0s - loss: 0.2844 - accuracy: 0.4830
Epoch 3: loss did not improve from 0.22952
1/1 [==============================] - 2s 2s/step
1/1 [==============================] - 20s 20s/step - loss: 0.2844 - accuracy: 0.4830
Epoch 4/20
1/1 [==============================] - ETA: 0s - loss: 0.2508 - accuracy: 0.5522
Epoch 4: loss did not improve from 0.22952
1/1 [==============================] - 2s 2s/step
1/1 [==============================] - 22s 22s/step - loss: 0.2508 - accuracy: 0.5522
Epoch 5/20
1/1 [==============================] - ETA: 0s - loss: 0.1503 - accuracy: 0.5717
Epoch 5: loss improved from 0.22952 to 0.15029, saving model to ckpt/suimnet_img_logger.hdf5
1/1 [==============================] - 2s 2s/step
1/1 [==============================] - 21s 21s/step - loss: 0.1503 - accuracy: 0.5717
Epoch 6/20
1/1 [==============================] - ETA: 0s - loss: 0.1393 - accuracy: 0.5713
Epoch 6: loss improved from 0.15029 to 0.13933, saving model to ckpt/suimnet_img_logger.hdf5
1/1 [==============================] - 2s 2s/step
1/1 [==============================] - 23s 23s/step - loss: 0.1393 - accuracy: 0.5713
Epoch 7/20
1/1 [==============================] - ETA: 0s - loss: 0.1538 - accuracy: 0.6212
Epoch 7: loss did not improve from 0.13933
1/1 [==============================] - 2s 2s/step
1/1 [==============================] - 22s 22s/step - loss: 0.1538 - accuracy: 0.6212
Epoch 8/20
1/1 [==============================] - ETA: 0s - loss: 0.1809 - accuracy: 0.5972
Epoch 8: loss did not improve from 0.13933
1/1 [==============================] - 2s 2s/step
1/1 [==============================] - 22s 22s/step - loss: 0.1809 - accuracy: 0.5972
Epoch 9/20
1/1 [==============================] - ETA: 0s - loss: 0.3000 - accuracy: 0.5062
Epoch 9: loss did not improve from 0.13933
1/1 [==============================] - 2s 2s/step
1/1 [==============================] - 22s 22s/step - loss: 0.3000 - accuracy: 0.5062
Epoch 10/20
1/1 [==============================] - ETA: 0s - loss: 0.1649 - accuracy: 0.6304
Epoch 10: loss did not improve from 0.13933
1/1 [==============================] - 2s 2s/step
1/1 [==============================] - 22s 22s/step - loss: 0.1649 - accuracy: 0.6304
Epoch 11/20
1/1 [==============================] - ETA: 0s - loss: 0.2270 - accuracy: 0.5558
Epoch 11: loss did not improve from 0.13933
1/1 [==============================] - 2s 2s/step
1/1 [==============================] - 21s 21s/step - loss: 0.2270 - accuracy: 0.5558
Epoch 12/20
1/1 [==============================] - ETA: 0s - loss: 0.3007 - accuracy: 0.5764
Epoch 12: loss did not improve from 0.13933
1/1 [==============================] - 2s 2s/step
1/1 [==============================] - 20s 20s/step - loss: 0.3007 - accuracy: 0.5764
Epoch 13/20
1/1 [==============================] - ETA: 0s - loss: 0.0954 - accuracy: 0.6664
Epoch 13: loss improved from 0.13933 to 0.09538, saving model to ckpt/suimnet_img_logger.hdf5
1/1 [==============================] - 2s 2s/step
1/1 [==============================] - 22s 22s/step - loss: 0.0954 - accuracy: 0.6664
Epoch 14/20
1/1 [==============================] - ETA: 0s - loss: 0.2314 - accuracy: 0.5499
Epoch 14: loss did not improve from 0.09538
1/1 [==============================] - 3s 3s/step
1/1 [==============================] - 21s 21s/step - loss: 0.2314 - accuracy: 0.5499
Epoch 15/20
1/1 [==============================] - ETA: 0s - loss: 0.2461 - accuracy: 0.6083
Epoch 15: loss did not improve from 0.09538
1/1 [==============================] - 2s 2s/step
1/1 [==============================] - 23s 23s/step - loss: 0.2461 - accuracy: 0.6083
Epoch 16/20
1/1 [==============================] - ETA: 0s - loss: 0.1140 - accuracy: 0.5377
Epoch 16: loss did not improve from 0.09538
1/1 [==============================] - 3s 3s/step
1/1 [==============================] - 24s 24s/step - loss: 0.1140 - accuracy: 0.5377
Epoch 17/20
1/1 [==============================] - ETA: 0s - loss: 0.2925 - accuracy: 0.4588
Epoch 17: loss did not improve from 0.09538
1/1 [==============================] - 2s 2s/step
1/1 [==============================] - 22s 22s/step - loss: 0.2925 - accuracy: 0.4588
Epoch 18/20
1/1 [==============================] - ETA: 0s - loss: 0.1915 - accuracy: 0.5514
Epoch 18: loss did not improve from 0.09538
1/1 [==============================] - 2s 2s/step
1/1 [==============================] - 22s 22s/step - loss: 0.1915 - accuracy: 0.5514
Epoch 19/20
1/1 [==============================] - ETA: 0s - loss: 0.2089 - accuracy: 0.5247
Epoch 19: loss did not improve from 0.09538
1/1 [==============================] - 3s 3s/step
1/1 [==============================] - 22s 22s/step - loss: 0.2089 - accuracy: 0.5247
Epoch 20/20
1/1 [==============================] - ETA: 0s - loss: 0.1313 - accuracy: 0.5399
Epoch 20: loss did not improve from 0.09538
1/1 [==============================] - 2s 2s/step
1/1 [==============================] - 21s 21s/step - loss: 0.1313 - accuracy: 0.5399